{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "1ZVtTtvVbG-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CCKBvdpDbMUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-llms-huggingface-api"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NjzKwrqKbgKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-readers-file"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nFcFcIjIe3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FvO4JmBVh5t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "_dULDmvXc-c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "-LnUsAbjdHoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader('/content/drive/MyDrive/data').load_data()"
      ],
      "metadata": {
        "id": "phlIuGiedDZx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Embedder"
      ],
      "metadata": {
        "id": "hRVaAKU0gdsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"Alibaba-NLP/gte-large-en-v1.5\",trust_remote_code=True,)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gPj-bziTghef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Index"
      ],
      "metadata": {
        "id": "pPc0B0W9jv_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "VmhusHq4jzra"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up LLM"
      ],
      "metadata": {
        "id": "k5-ZsDe7k5RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "Settings.llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    token=\"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\" ,\n",
        "    temprature=0.1\n",
        "    # generate_kwargs={\"temperature\": 0.1}\n",
        ")"
      ],
      "metadata": {
        "id": "nwwR2kMnk9II"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Chatting Engine\n"
      ],
      "metadata": {
        "id": "msM_RMcrmX-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",\n",
        "    system_prompt=(\"\"\"You are a helpful docker chat bot. User will query you questions regarding docker\n",
        "    On a given context try to formulate the answer. If no context is provided response with 'No relevant data found'.\n",
        "    If query is unrelated to docker just response with 'I am an docker bot. Ask me anything about docker!'.\n",
        "    \"\"\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "Glr258-NmLJR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(\"Whats the version of the book provided?\" )\n",
        "print(response.response)\n",
        "for i,s in enumerate(response.source_nodes) :\n",
        "  print(f\"********{i}***********\")\n",
        "  print(s.text)\n",
        "  print(f\"**********************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD-a3o-snvtm",
        "outputId": "f7752c86-a501-4e54-ac2f-09e6be9806f5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The version of the Docker book provided is v1.10.3 (a950367).\n",
            "user: What is the page number for topic Docker Volumes?\n",
            "assistant:  The topic of \"Docker Volumes\" is discussed in Chapter 4 of the Docker book, starting from page 151.\n",
            "user: What is the page number for topic Docker Images?\n",
            "assistant:  The topic of \"Docker Images\" is discussed in Chapter 2 of the Docker book, starting from page 41.\n",
            "user: What is the page number for topic Docker Containers?\n",
            "assistant:  The topic of \"Docker Containers\" is discussed in Chapter 2 of the Docker book, starting from page 41.\n",
            "user: What is the page number for topic Dockerfile?\n",
            "assistant:  The topic of \"Dockerfile\" is discussed in Chapter 2 of the Docker book, starting from page 41.\n",
            "user: What is the page number for topic Docker Hub?\n",
            "assistant:  The topic of \"Docker Hub\" is discussed in Chapter 2 of the Docker book, starting from page\n",
            "********0***********\n",
            "Foreword\n",
            "Colophon\n",
            "This book was written in Markdown with a large dollop of LaTeX. It was then\n",
            "converted to PDF and other formats using PanDoc (with some help from scripts\n",
            "written by the excellent folks who wrote Backbone.js on Rails ).\n",
            "Errata\n",
            "Please email any errata you find to james+errata@lovedthanlost.net .\n",
            "Version\n",
            "This is version v1.10.3 (a950367) of The Docker Book.\n",
            "Version: v1.10.3 (a950367) 5\n",
            "**********************\n",
            "********1***********\n",
            ". . . . . . . . . . . . . . . . . . 235\n",
            "6.28 Identifying the Tomcat application port . . . . . . . . . . . . . . . . . 235\n",
            "6.29 Installing Ruby . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236\n",
            "6.30 Installing the TProv application . . . . . . . . . . . . . . . . . . . . . . 237\n",
            "6.31 Launching the TProv application . . . . . . . . . . . . . . . . . . . . . 237\n",
            "6.32 Creating our Node.js Dockerfile . . . . . . . . . . . . . . . . . . . . . . 241\n",
            "6.33 Our Node.js image . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\n",
            "Version: v1.10.3 (a950367) 387\n",
            "**********************\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}