{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "1ZVtTtvVbG-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CCKBvdpDbMUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-llms-huggingface-api"
      ],
      "metadata": {
        "id": "NjzKwrqKbgKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-readers-file"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nFcFcIjIe3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FvO4JmBVh5t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "_dULDmvXc-c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "-LnUsAbjdHoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader('/content/drive/MyDrive/data').load_data()"
      ],
      "metadata": {
        "id": "phlIuGiedDZx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Embedder"
      ],
      "metadata": {
        "id": "hRVaAKU0gdsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"Alibaba-NLP/gte-large-en-v1.5\",trust_remote_code=True,)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gPj-bziTghef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Index"
      ],
      "metadata": {
        "id": "pPc0B0W9jv_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "VmhusHq4jzra"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up LLM"
      ],
      "metadata": {
        "id": "k5-ZsDe7k5RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "Settings.llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    # model_name=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
        "    token=\"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\" ,\n",
        "    generate_kwargs={\"temperature\": 0.1}\n",
        ")"
      ],
      "metadata": {
        "id": "nwwR2kMnk9II"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Chatting Engine\n"
      ],
      "metadata": {
        "id": "msM_RMcrmX-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",\n",
        "    system_prompt=(\n",
        "        \"\"\"\n",
        "        You are a Docker-focused assistant within a retrieval-augmented generation (RAG) system. You must answer questions exclusively based on the provided context data.\n",
        "        Do not use any knowledge outside of the provided context under any circumstances.\n",
        "\n",
        "        Guidelines:\n",
        "        1. **Only Context-Based Answers**: Respond only with information explicitly present in the context. If the context does not contain an answer, respond with “No relevant data found.”\n",
        "        2. **Do Not Use Pre-trained Knowledge**: Ignore all pre-trained knowledge, assumptions, or general information. Answer only from the context.\n",
        "        3. **Unrelated Questions**: If a user’s query is outside the scope of Docker or the context, reply with “I am a Docker assistant. Please ask questions related to Docker.”\n",
        "        4. **Repeated Queries**: If the same question is repeated, provide the same answer without additions and rephrasing.\n",
        "        5. **Concise Responses**: Keep responses short and accurate.\n",
        "\n",
        "        Important: Do not use or rely on general information outside of what is provided in the context. If unclear, respond with “No relevant data found.”\n",
        "        \"\"\"\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Glr258-NmLJR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(\"What is javascript?\" )\n",
        "print(response.response)\n",
        "for i,s in enumerate(response.source_nodes) :\n",
        "  print(f\"********{i}***********\")\n",
        "  print(s.text)\n",
        "  print(f\"**********************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD-a3o-snvtm",
        "outputId": "43d20a70-d453-4398-df87-2dfe47b7d3f8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No relevant data found. I am a Docker-focused assistant. Please ask questions related to Docker.\n",
            "********0***********\n",
            "Chapter 6: Building services with Docker\n",
            "Listing 6.34 :Our Node.js server.js application\n",
            ". . .\n",
            "var logFile = fs.createWriteStream('/var/log/nodeapp/nodeapp.log\n",
            "', {flags: 'a'});\n",
            "app.configure(function() {\n",
            ". . .\n",
            "app.use(express.session({\n",
            "store: new RedisStore({\n",
            "host: process.env.REDIS_HOST || 'redis_primary',\n",
            "port: process.env.REDIS_PORT || 6379,\n",
            "db: process.env.REDIS_DB || 0\n",
            "}),\n",
            "cookie: {\n",
            ". . .\n",
            "app.get('/', function(req, res) {\n",
            "res.json({\n",
            "status: \"ok\"\n",
            "});\n",
            "});\n",
            ". . .\n",
            "var port = process.env.HTTP_PORT || 3000;\n",
            "server.listen(port);\n",
            "console.log('Listening on port ' + port);\n",
            "Version: v1.10.3 (a950367) 243\n",
            "**********************\n",
            "********1***********\n",
            "Chapter 1: Introduction\n",
            "processes. Attackers, if they breach the running process in the jail, then find\n",
            "themselves trapped in this environment and unable to further compromise a host.\n",
            "More recent container technologies have included OpenVZ , Solaris Zones, and\n",
            "Linux containers like lxc. Using these more recent technologies, containers can\n",
            "now look like full-blown hosts in their own right rather than just execution envi-\n",
            "ronments. In Docker’s case, having modern Linux kernel features, such as control\n",
            "groups and namespaces, means that containers can have strong isolation, their\n",
            "own network and storage stacks, as well as resource management capabilities to\n",
            "allow friendly co-existence of multiple containers on a host.\n",
            "Containers are generally considered a lean technology because they require lim-\n",
            "ited overhead. Unlike traditional virtualization or paravirtualization technologies,\n",
            "they do not require an emulation layer or a hypervisor layer to run and instead\n",
            "use the operating system’s normal system call interface. This reduces the over-\n",
            "head required to run containers and can allow a greater density of containers to\n",
            "run on a host.\n",
            "Despite their history containers haven’t achieved large-scale adoption. A large\n",
            "part of this can be laid at the feet of their complexity: containers can be complex,\n",
            "hard to set up, and difficult to manage and automate. Docker aims to change that.\n",
            "Introducing Docker\n",
            "Docker is an open-source engine that automates the deployment of applications\n",
            "into containers. It was written by the team at Docker, Inc (formerly dotCloud Inc,\n",
            "an early player in the Platform-as-a-Service (PAAS) market), and released by them\n",
            "under the Apache 2.0 license.\n",
            "NOTE Disclaimer and disclosure: I am an advisor at Docker.\n",
            "So what is special about Docker? Docker adds an application deployment engine\n",
            "on top of a virtualized container execution environment. It is designed to provide\n",
            "a lightweight and fast environment in which to run your code as well as an efficient\n",
            "Version: v1.10.3 (a950367) 7\n",
            "**********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine.reset()"
      ],
      "metadata": {
        "id": "nnopQBzz5hcI"
      },
      "execution_count": 73,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}